train.car <- sample(seq_len(nrow(Carseats)), size = 250)
test.car <- Carseats[-train.car]
test.car
train.car
train.car <- Carseats[train.car]
test.car <- Carseats[-train.car]
Carseats
Carseats@data
data@Carseats
High=ifelse(Sales <=8,"No","Yes ")
Carseats =data.frame(Carseats ,High)
High=ifelse(Sales <=8,"No","Yes")
Carseats =data.frame(Carseats ,High)
Carseats
ncol(Carseats)
train.car <- sample(seq_len(nrow(Carseats)), size = 250)
train.car
train.car <- Carseats[train.car]
train.car <- Carseats[train.car,]
test.car <- Carseats[-train.car,]
test.car <- Carseats[-train.car,]
test.car
train.car
test.car <- Carseats[- train.car,]
tree.carseats =tree(High~.-Sales , train.car)
summary(tree.carseats)
OJ
train.oj <- sample(seq_len(nrow(OJ)), size = 800)
train.oj <- Carseats[train.oj,]
train.oj
train <- sample(seq_len(nrow(OJ)), size = 800)
train.oj <- Carseats[train,]
test.car <- Carseats[-train,]
test.car
train <- sample(seq_len(nrow(OJ)), size = 800)
train.oj <- OJ[train,]
test.car <- OJ[-train,]
train <- sample(seq_len(nrow(OJ)), size = 800)
train.oj <- OJ[train,]
test.oj <- OJ[-train,]
test.oj
tree.oj =tree(Purchase~., train.oj)
set.seed(10)
train <- sample(seq_len(nrow(OJ)), size = 800)
train.oj <- OJ[train,]
test.oj <- OJ[-train,]
tree.oj =tree(Purchase~., train.oj)
summary(tree.oj)
tree.oj
plot(tree.oj)
text(tree.oj, pretty = 0)
tree.pred <- predict(tree.oj ,test.oj ,type="class")
tree.pred
tree.pred <- predict(tree.oj ,test.oj ,type="class")
cv.oj =cv.tree(tree.oj , FUN=prune.misclass )
cv.oj
names(cv.oj)
plot(cv.oj$size, cv.oj$dev)
tree.pred <- predict(tree.oj ,test.oj ,type="class")
cv.oj =cv.tree(tree.oj)
plot(cv.oj$size, cv.oj$dev)
cv.oj
plot(cv.oj$size, cv.oj$dev, type = "b")
prune.oj <-  prune.misclass(tree.oj, best = 10)
# tree 5 have the lowest error
prune.oj <-  prune.misclass(tree.oj, best = 15)
# tree 5 have the lowest error
prune.oj <-  prune.misclass(tree.oj, best = 50)
# tree 5 have the lowest error
prune.oj <-  prune.misclass(tree.oj, best = 10)
# tree 5 have the lowest error
prune.oj <-  prune.misclass(tree.oj, best = 7)
tree.pred.prune <- predict(prune.oj, test.oj, type = "class")
table(tree.pred, test.oj)
table(tree.pred, test.oj$Purchase)
table(tree.pred.prune, test.oj$Purchase)
table(tree.pred.prune, train.oj$Purchase)
prune.oj <-  prune.misclass(tree.oj, best = 5)
tree.pred.prune <- predict(prune.oj, test.oj, type = "class")
table(tree.pred.prune, test.oj$Purchase)
# tree 5 have the lowest error
prune.oj <-  prune.misclass(tree.oj, best = 2)
tree.pred.prune <- predict(prune.oj, test.oj, type = "class")
table(tree.pred.prune, test.oj$Purchase)
# tree.pred.prune  CH  MM
#             CH 135  20
#             MM  27  88
#10
Hitters
#10
salary <- na.omit(Hitters[,'Salary'])
salary
#10
na.omit(Hitters[,'Salary'])
#10
na.omit(Hitters)
log.salary <- log(Hitters[,'Salary'])
log.salary
Hit <- na.omit(Hitters)
Hit
fix(Hit)
log.salary <- log(Hit[,'Salary'])
log.salary
Hit <- cbind(log.salary, Hit)
Hit
set.seed(0)
train <- sample(seq_len(nrow(Hit)), size = 200)
train.hit <- Hit[train,]
test.hit <- Hit[-train,]
train <- Hit[1:200,]
train
train <- c(1:200)
train.hit <- Hit[train,]
test.hit <- Hit[-train,]
nrow(train.hit)
nrow(test.hit)
boost.hit=gbm(log.salar~.,data=train.hit, distribution=
"gaussian ",n.trees=1000, interaction.depth=4)
library(gbm)
install.packages("gbm")
install.packages("gbm")
set.seed(0)
boost.hit=gbm(log.salar~.,data=train.hit, distribution=
"gaussian ",n.trees=1000, interaction.depth=4)
install.packages("gbm")
set.seed(0)
boost.hit=gbm(log.salar~.,data=train.hit, distribution=
"gaussian ",n.trees=1000, interaction.depth=4)
install.packages("gbm")
library(gbm)
set.seed(0)
boost.hit=gbm(log.salar~.,data=train.hit, distribution=
"gaussian ",n.trees=1000, interaction.depth=4)
names(train.hit)
boost.hit=gbm(log.salary~.,data=train.hit, distribution=
"gaussian ",n.trees=1000, interaction.depth=4)
boost.hit=gbm(log.salary~.,data=train.hit, distribution=
"gaussian",n.trees=1000, interaction.depth=4)
summary(boost.hit)
set.seed(0)
boost.hit=gbm(log.salary~.-salary,data=train.hit, distribution=
"gaussian",n.trees=1000, interaction.depth=4)
set.seed(0)
boost.hit=gbm(log.salary~.-Salary,data=train.hit, distribution=
"gaussian",n.trees=1000, interaction.depth=4)
summary(boost.hit)
shrinkage <- c(0.1, 0.2, 0.3, 0.4, 0.5)
for (i in shrinkage) {
boost.hit = gbm(log.salary~.,data=train.hit, distribution=
"gaussian ",n.trees =5000, interaction.depth =4, shrinkage =i,
verbose=F)
hit.boost=predict (boost.boston ,newdata =test.hitse,
n.trees=5000)
}
shrinkage <- c(0.1, 0.2, 0.3, 0.4, 0.5)
for (i in shrinkage) {
boost.hit = gbm(log.salary~.,data=train.hit, distribution=
"gaussian",n.trees =5000, interaction.depth =4, shrinkage =i,
verbose=F)
hit.boost=predict (boost.boston ,newdata =test.hitse,
n.trees=5000)
}
shrinkage <- c(0.1, 0.2, 0.3, 0.4, 0.5)
for (i in shrinkage) {
boost.hit = gbm(log.salary~.,data=train.hit, distribution=
"gaussian",n.trees =5000, interaction.depth =4, shrinkage =i,
verbose=F)
hit.boost=predict (boost.hit ,newdata =test.hitse,
n.trees=5000)
}
shrinkage <- c(0.1, 0.2, 0.3, 0.4, 0.5)
for (i in shrinkage) {
boost.hit = gbm(log.salary~.,data=train.hit, distribution=
"gaussian",n.trees =5000, interaction.depth =4, shrinkage =i,
verbose=F)
hit.boost=predict (boost.hit ,newdata =test.hit,
n.trees=5000)
}
for (i in shrinkage) {
boost.hit = gbm(log.salary~.,data=train.hit, distribution=
"gaussian",n.trees =5000, interaction.depth =4, shrinkage =i,
verbose=F)
hit.boost=predict (boost.hit ,newdata =test.hit,
n.trees=5000)
mean((hit.boost - test.hit)^2)
}
# import packages
if(!require(xlsx)){
install.packages("xlsx")
}
require(xlsx)
# load the 8D data into a data frame
AllDataCities <- read.xlsx("oecd_cities_stats.xlsx", sheetName = "OECD.Stat export")
setwd("//WURNET.NL/Homes/azuma001/AppData/FolderRedirection/Desktop/machine_learning_week3")
AllDataCities <- read.xlsx("oecd_cities_stats.xlsx", sheetName = "OECD.Stat export")
# extract a subset of the data frame to remove unwanted rows and columns
DataCities<-subset(AllDataCities,NA..9!='..' & NA..15!='..',select=c(NA..1,NA..3,NA..5,NA..7,NA..9,NA..11,NA..13,NA..15))
AllDataCities
View(AllDataCities)
View(AllDataCities)
DataCities
View(DataCities)
View(DataCities)
# extract the country codes correspoinding to each city
# note the use of the apply() function and check what it does. You will need it later
Cities<-subset(AllDataCities,NA..9!='..' & NA..15!='..',select=FALSE.)
View(Cities)
View(Cities)
Cities <- apply(Cities,2,as.character)
View(Cities)
View(Cities)
View(Cities)
Cities <- apply(Cities,2,as.character)
Cities
# extract the country codes correspoinding to each city
# note the use of the apply() function and check what it does. You will need it later
Cities<-subset(AllDataCities,NA..9!='..' & NA..15!='..',select=FALSE.)
CountryCodes<-apply(Cities,1,function(x) substr(strsplit(x,": ")[[1]][1],3,4))
CountryCodes
?strsplit
CountryCodes<-apply(Cities,1,function(x) substr(strsplit(x,": ")[[2]][1],3,4))
CountryCodes<-apply(Cities,1,function(x) substr(strsplit(x,": ")[[1]][1],3,4))
CountryCodes<-apply(Cities,1,function(x) substr(strsplit(x,": ")[[1]][2],3,4))
CountryCodes
CountryCodes<-apply(Cities,1,function(x) substr(strsplit(x,": ")[[1]][1],3,4))
CountryCodes<-apply(Cities,1,function(x) substr(strsplit(x,": ")[[2]][1],3,4))
CountryCodes<-apply(Cities,1,function(x) substr(strsplit(x,": ")[[1]][1],3,4))
# load a Look-up-table containing the contry codes, names and world regions
CountryLUT <- read.xlsx("oecd_cities_stats.xlsx", sheetName = "Countries")
# extract the coutry names and change the variable names
CountryNames<-matrix(sapply(CountryCodes,function(x) CountryLUT[1,which(x==names(CountryLUT))]))
RegionNames<-matrix(sapply(CountryCodes,function(x) CountryLUT[2,which(x==names(CountryLUT))]))
CityNames<-apply(Cities,1,function(x) strsplit(x,": ")[[1]][2])
VarNames<-c('Population','Youth dep. ratio', 'Old-age dep. ratio','Density','Green area per cap.','Core concentration', 'P2.5 pollution','Unemplyment')
names(DataCities)<-VarNames
rownames(DataCities)<-CityNames
CountryCodes<-apply(Cities,1,function(x) substr(strsplit(x,": ")[[1]][1]))
CountryCodes<-apply(Cities,1,function(x) substr(strsplit(x,": ")[[1]][1], 2))
CountryCodes<-apply(Cities,1,function(x) substr(strsplit(x,": ")[[1]][1], 2, 3))
CountryCodes
CountryCodes<-apply(Cities,1,function(x) substr(strsplit(x,": ")[[1]][1], 3, 4))
CountryCodes
CountryCodes<-apply(Cities,1,function(x) substr(strsplit(x,": ")[[1]][1],2, 4))
CountryCodes
# load a Look-up-table containing the contry codes, names and world regions
CountryLUT <- read.xlsx("oecd_cities_stats.xlsx", sheetName = "Countries")
# extract the coutry names and change the variable names
CountryNames<-matrix(sapply(CountryCodes,function(x) CountryLUT[1,which(x==names(CountryLUT))]))
RegionNames<-matrix(sapply(CountryCodes,function(x) CountryLUT[2,which(x==names(CountryLUT))]))
CityNames<-apply(Cities,1,function(x) strsplit(x,": ")[[1]][2])
VarNames<-c('Population','Youth dep. ratio', 'Old-age dep. ratio','Density','Green area per cap.','Core concentration', 'P2.5 pollution','Unemplyment')
names(DataCities)<-VarNames
rownames(DataCities)<-CityNames
# here is some code to plot all pairs of variables
# maybe not the easiest way to see what's going on, although you can if you put some effort
pairs(DataCities,col=sapply(RegionNames,FUN=function(x) which.max(unique(RegionNames) == x)),oma=c(3,3,5,15),pch=19)
par(xpd=TRUE)
legend(0.87, 0.8, as.vector(unique(RegionNames)),  fill=palette() )
# extract the coutry names and change the variable names
CountryNames<-matrix(sapply(CountryCodes,function(x) CountryLUT[1,which(x==names(CountryLUT))]))
RegionNames<-matrix(sapply(CountryCodes,function(x) CountryLUT[2,which(x==names(CountryLUT))]))
CityNames<-apply(Cities,1,function(x) strsplit(x,": ")[[1]][2])
VarNames<-c('Population','Youth dep. ratio', 'Old-age dep. ratio','Density','Green area per cap.','Core concentration', 'P2.5 pollution','Unemplyment')
names(DataCities)<-VarNames
rownames(DataCities)<-CityNames
# here is some code to plot all pairs of variables
# maybe not the easiest way to see what's going on, although you can if you put some effort
pairs(DataCities,col=sapply(RegionNames,FUN=function(x) which.max(unique(RegionNames) == x)),oma=c(3,3,5,15),pch=19)
par(xpd=TRUE)
legend(0.87, 0.8, as.vector(unique(RegionNames)),  fill=palette() )
# load a Look-up-table containing the contry codes, names and world regions
CountryLUT <- read.xlsx("oecd_cities_stats.xlsx", sheetName = "Countries")
# extract the coutry names and change the variable names
CountryNames<-matrix(sapply(CountryCodes,function(x) CountryLUT[1,which(x==names(CountryLUT))]))
RegionNames<-matrix(sapply(CountryCodes,function(x) CountryLUT[2,which(x==names(CountryLUT))]))
CityNames<-apply(Cities,1,function(x) strsplit(x,": ")[[1]][2])
VarNames<-c('Population','Youth dep. ratio', 'Old-age dep. ratio','Density','Green area per cap.','Core concentration', 'P2.5 pollution','Unemplyment')
names(DataCities)<-VarNames
rownames(DataCities)<-CityNames
# --------------------------------------------------------------------------------------------
# 2. Visually explore the world cities dataset
# --------------------------------------------------------------------------------------------
# here is some code to plot all pairs of variables
# maybe not the easiest way to see what's going on, although you can if you put some effort
pairs(DataCities,col=sapply(RegionNames,FUN=function(x) which.max(unique(RegionNames) == x)),oma=c(3,3,5,15),pch=19)
par(xpd=TRUE)
legend(0.87, 0.8, as.vector(unique(RegionNames)),  fill=palette() )
# load the 8D data into a data frame
AllDataCities <- read.xlsx("oecd_cities_stats.xlsx", sheetName = "OECD.Stat export")
# extract a subset of the data frame to remove unwanted rows and columns
DataCities<-subset(AllDataCities,NA..9!='..' & NA..15!='..',select=c(NA..1,NA..3,NA..5,NA..7,NA..9,NA..11,NA..13,NA..15))
# extract the country codes correspoinding to each city
# note the use of the apply() function and check what it does. You will need it later
Cities<-subset(AllDataCities,NA..9!='..' & NA..15!='..',select=FALSE.)
Cities <- apply(Cities,2,as.character)
CountryCodes<-apply(Cities,1,function(x) substr(strsplit(x,": ")[[1]][1],3, 4))
# load a Look-up-table containing the contry codes, names and world regions
CountryLUT <- read.xlsx("oecd_cities_stats.xlsx", sheetName = "Countries")
# extract the coutry names and change the variable names
CountryNames<-matrix(sapply(CountryCodes,function(x) CountryLUT[1,which(x==names(CountryLUT))]))
RegionNames<-matrix(sapply(CountryCodes,function(x) CountryLUT[2,which(x==names(CountryLUT))]))
CityNames<-apply(Cities,1,function(x) strsplit(x,": ")[[1]][2])
VarNames<-c('Population','Youth dep. ratio', 'Old-age dep. ratio','Density','Green area per cap.','Core concentration', 'P2.5 pollution','Unemplyment')
names(DataCities)<-VarNames
rownames(DataCities)<-CityNames
# --------------------------------------------------------------------------------------------
# 2. Visually explore the world cities dataset
# --------------------------------------------------------------------------------------------
# here is some code to plot all pairs of variables
# maybe not the easiest way to see what's going on, although you can if you put some effort
pairs(DataCities,col=sapply(RegionNames,FUN=function(x) which.max(unique(RegionNames) == x)),oma=c(3,3,5,15),pch=19)
par(xpd=TRUE)
legend(0.87, 0.8, as.vector(unique(RegionNames)),  fill=palette() )
source("my_kmeans.R")
DataCities
DataCities<-apply(DataCities,2,as.numeric)
DataCities.scale <- scale(DataCities)
K<- c(3:5)
k
K
for (i in K){
my_kmeans(DataCities, K=i)
}
require(xlsx)
if(!require(pracma)){
install.packages("pracma")
}
install.packages("pracma")
DataCities<-apply(DataCities,2,as.numeric)
DataCities.scale <- scale(DataCities)
K<- c(3:5)
for (i in K){
my_kmeans(DataCities, K=i)
}
for (i in K){
kmean <- kmeans(DataCities, K=i, nstart=20)
}
for (i in K){
kmean <- kmeans(DataCities, k=i, nstart=20)
}
for (i in K){
kmean <- kmeans(DataCities, i, nstart=20)
}
K<- c(3:5)
for (i in K){
kmean <- kmeans(DataCities, i, nstart=20)
}
K<- c(3:5)
for (i in K){
kmean[i,] <- kmeans(DataCities, i, nstart=20)
}
for (i in K){
kmean[i,] <- kmeans(DataCities, i, nstart=20)
}
for (i in K){
kmean[i] <- kmeans(DataCities, i, nstart=20)
}
kmean
names(kmean)
clustering <- kmean$cluster #? get the clustering of the cities
par(mfrow=c(2, ceiling(K/2)))
for (i in 1:K) {
barplot(clustering$centers[i,]-colMeans(clustering$centers),names.arg=VarNames,las=2)
}
DataCities<-apply(DataCities,2,as.numeric)
DataCities.scale <- scale(DataCities)
K<- 3
kmean <- kmeans(DataCities, K, nstart=20)
clustering <- kmean$cluster
par(mfrow=c(2, ceiling(K/2)))
for (i in 1:K) {
barplot(clustering$centers[i,]-colMeans(clustering$centers),names.arg=VarNames,las=2)
}
DataCities<-apply(DataCities,2,as.numeric)
DataCities.scale <- scale(DataCities)
K<- 3
clustering <-kmeans(DataCities, K, nstart=20) #? get the clustering of the cities
################################
# Plot the cluster centroids as barplots
par(mfrow=c(2, ceiling(K/2)))
for (i in 1:K) {
barplot(clustering$centers[i,]-colMeans(clustering$centers),names.arg=VarNames,las=2)
}
DataCities<-apply(DataCities,2,as.numeric)
DataCities.scale <- scale(DataCities)
K<- 3
clustering <-kmeans(DataCities.scale, K, nstart=20) #? get the clustering of the cities
################################
# Plot the cluster centroids as barplots
par(mfrow=c(2, ceiling(K/2)))
for (i in 1:K) {
barplot(clustering$centers[i,]-colMeans(clustering$centers),names.arg=VarNames,las=2)
}
# 2
for (j in K) {
clustering[j,] <-kmeans(DataCities.scale, j, nstart=20) #? get the clustering of the cities
################################
# Plot the cluster centroids as barplots
par(mfrow=c(2, ceiling(j/2)))
for (i in 1:K) {
barplot(clustering$centers[i,]-colMeans(clustering$centers),names.arg=VarNames,las=2)
}
}
for (j in K) {
clustering[j] <-kmeans(DataCities.scale, j, nstart=20) #? get the clustering of the cities
################################
# Plot the cluster centroids as barplots
par(mfrow=c(2, ceiling(j/2)))
for (i in 1:K) {
barplot(clustering$centers[i,]-colMeans(clustering$centers),names.arg=VarNames,las=2)
}
}
for (k in K) {
clustering[k] <-kmeans(DataCities, k, nstart=20) #? get the clustering of the cities
################################
}
clustering
K<- c(3:5)
for (k in K) {
clustering <-kmeans(DataCities, k, nstart=20) #? get the clustering of the cities
################################
# Plot the cluster centroids as barplots
par(mfrow=c(2, ceiling(K/2)))
for (i in 1:K) {
barplot(clustering$centers[i,]-colMeans(clustering$centers),names.arg=VarNames,las=2)
}
}
for (k in K) {
clustering <-kmeans(DataCities, k, nstart=20) #? get the clustering of the cities
################################
# Plot the cluster centroids as barplots
par(mfrow=c(2, ceiling(k/2)))
for (i in 1:K) {
barplot(clustering$centers[i,]-colMeans(clustering$centers),names.arg=VarNames,las=2)
}
}
K<- c(3:5)
for (k in K) {
clustering <-kmeans(DataCities, k, nstart=20) #? get the clustering of the cities
################################
# Plot the cluster centroids as barplots
par(mfrow=c(2, ceiling(k/2)))
for (i in 1:k) {
barplot(clustering$centers[i,]-colMeans(clustering$centers),names.arg=VarNames,las=2)
}
}
for (k in K) {
clustering <-kmeans(DataCities.scale, k, nstart=20) #? get the clustering of the cities
################################
# Plot the cluster centroids as barplots
par(mfrow=c(2, ceiling(k/2)))
for (i in 1:k) {
barplot(clustering$centers[i,]-colMeans(clustering$centers),names.arg=VarNames,las=2)
}
}
?piechart
?pie
clustering$centers[i,]-colMeans(clustering$centers)
clustering$centers
pie(clustering$centers[i,]-colMeans(clustering$centers))
DataCities.scale
par(mfrow=c(2, ceiling(K/2)))
for (i in 1:K) {
pie(table(RegionNames, clustering$cluster)[,1])
}
for (i in 1:K) {
par(mfrow=c(2, ceiling(i/2)))
pie(table(RegionNames, clustering$cluster)[,1])
}
par(mfrow=c(2, ceiling(i/2)))
for (i in 1:K) {
pie(table(RegionNames, clustering$cluster)[,1])
}
par(mfrow=c(2, ceiling(i/2)))
for (i in K) {
pie(table(RegionNames, clustering$cluster)[,1])
}
par(mfrow=c(2, ceiling(i/2)))
for (i in K) {
pie(table(RegionNames, clustering$cluster)[,i])
}
par(mfrow=c(2, ceiling(i/2)))
for (i in 1:K) {
pie(table(RegionNames, clustering$cluster)[,i])
}
par(mfrow=c(2, ceiling(i/2)))
for (i in 1:5) {
pie(table(RegionNames, clustering$cluster)[,i])
}
for (i in K) {
par(mfrow=c(2, ceiling(i/2)))
pie(table(RegionNames, clustering$cluster)[,i])
}
for (i in 1:5) {
par(mfrow=c(2, ceiling(i/2)))
pie(table(RegionNames, clustering$cluster)[,i])
}
par(mfrow=c(2, ceiling(5/2)))
for (i in 1:5) {
pie(table(RegionNames, clustering$cluster)[,i])
}
pca<- prcomp(DataCities.scale)
pca<- prcomp(DataCities.scale)#? PCA of DataCities
source('ggbiplot.R')
#? use ggbiplot to visualize. Type ggbiplot to see the code and the options
ggbiplot(pca)
pca<- prcomp(DataCities.scale)#? PCA of DataCities
source('ggbiplot.R')
#? use ggbiplot to visualize. Type ggbiplot to see the code and the options
ggbiplot(pca)
DataCities.scale
RegionNames
